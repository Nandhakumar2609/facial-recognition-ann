{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Face Recognition System with Personal Information Retrieval Using Deep Learning**"
      ],
      "metadata": {
        "id": "ZDu-HCtrj2cL"
      },
      "id": "ZDu-HCtrj2cL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction:**\n",
        "\n",
        "This project implements a robust face recognition system leveraging deep learning techniques and the FaceNet architecture for feature extraction. The system identifies individuals from images by extracting facial embeddings and classifying them using a Multi-Layer Perceptron (MLP) neural network. Beyond simple recognition, the system can also retrieve and display relevant personal information such as age, gender, nationality, role, and other attributes stored in a structured CSV file. The pipeline supports both single-image inference and batch processing of multiple images, enabling flexible real-world applications such as access control, actor identification, or personalized recommendations. The solution is designed to be efficient, scalable, and compatible with GPU acceleration for faster training and inference."
      ],
      "metadata": {
        "id": "XqQK_uGij7VZ"
      },
      "id": "XqQK_uGij7VZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imports and Library Setup for Face Recognition and Classification Pipeline**"
      ],
      "metadata": {
        "id": "ueRNghR0g1tA"
      },
      "id": "ueRNghR0g1tA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85678d80-036e-445f-9cc8-7fcc02e5f71d",
      "metadata": {
        "id": "85678d80-036e-445f-9cc8-7fcc02e5f71d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import face_recognition\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Face Recognition Pipeline: Data Preparation, Model Training, Evaluation, and Inference**"
      ],
      "metadata": {
        "id": "xifbYWe_hPAE"
      },
      "id": "xifbYWe_hPAE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1393c13-c399-4eb8-b86f-a109b54ba53c",
      "metadata": {
        "id": "f1393c13-c399-4eb8-b86f-a109b54ba53c",
        "outputId": "146b7559-6174-496a-cdc8-f3cb69c13c6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Angelina Jolie\\044_512dfd33.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Angelina Jolie\\049_4d6df392.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Angelina Jolie\\092_26130bb1.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Angelina Jolie\\095_0be163a1.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Brad Pitt\\041_cc0957bf.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Brad Pitt\\048_185402c6.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Brad Pitt\\060_136e5ef5.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Brad Pitt\\076_75b9dd73.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Brad Pitt\\095_1104d364.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Brad Pitt\\100_f4b2c7a7.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Denzel Washington\\012_6b8f22bf.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Denzel Washington\\026_2f832037.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Denzel Washington\\034_e09c630c.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Denzel Washington\\040_e534b74f.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Denzel Washington\\048_cd8dc27d.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Denzel Washington\\055_fbbcb3c7.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Denzel Washington\\059_3b848154.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Denzel Washington\\061_6bf34908.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Denzel Washington\\063_7656840a.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Denzel Washington\\083_9436dbb0.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Denzel Washington\\093_4027b1e2.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Denzel Washington\\100_26562919.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Hugh Jackman\\032_0e6a520a.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Hugh Jackman\\045_24b44c3d.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Hugh Jackman\\085_394c2c3c.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Hugh Jackman\\091_2ace2ad8.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Hugh Jackman\\095_b464eda0.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Jennifer Lawrence\\007_72ad75ba.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Jennifer Lawrence\\030_4f246d8f.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Jennifer Lawrence\\032_bed86546.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Johnny Depp\\043_77e393de.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Johnny Depp\\065_6f1ed846.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Johnny Depp\\081_059a278c.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Johnny Depp\\083_16b5e7ab.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Johnny Depp\\096_78a5a076.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Kate Winslet\\007_572cf58c.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Kate Winslet\\044_c2d670fb.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Kate Winslet\\048_453e6cb3.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Kate Winslet\\050_0c20b215.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Kate Winslet\\057_b1a0b23b.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Kate Winslet\\061_9885f065.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Kate Winslet\\086_c7665b8f.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Leonardo DiCaprio\\039_d49e8191.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Leonardo DiCaprio\\047_ce57f03b.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Leonardo DiCaprio\\066_f048ba09.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Leonardo DiCaprio\\067_a0efbd88.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Leonardo DiCaprio\\070_ae3a4fa0.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Leonardo DiCaprio\\086_a1441427.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Megan Fox\\041_139bb2a5.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Megan Fox\\054_5a9566eb.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Megan Fox\\061_d844ec74.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Megan Fox\\079_4e33cd00.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Natalie Portman\\009_3300e98f.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Natalie Portman\\038_4930b73f.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Natalie Portman\\049_f7490e79.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Natalie Portman\\061_029fc37f.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Natalie Portman\\088_c6c7b0b2.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Nicole Kidman\\057_72a1674e.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Nicole Kidman\\070_a4bd7cf0.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Nicole Kidman\\083_b9c10851.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Nicole Kidman\\084_1eb9844d.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Robert Downey Jr\\031_f2f3733f.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Robert Downey Jr\\050_7509d1bb.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Robert Downey Jr\\093_8bbca2a0.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Sandra Bullock\\028_5388c983.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Sandra Bullock\\043_4f352240.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Sandra Bullock\\051_6e09f63c.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Sandra Bullock\\053_ae92d5b1.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Sandra Bullock\\078_d9a9ca25.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Sandra Bullock\\084_6b81d36b.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Scarlett Johansson\\050_c8461888.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Scarlett Johansson\\090_8e8d0b5c.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Scarlett Johansson\\092_4c27282f.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Scarlett Johansson\\152_a5f9d1a6.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Scarlett Johansson\\198_e056989e.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Tom Cruise\\043_be7cc0ea.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Tom Cruise\\049_78b42871.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Tom Cruise\\080_566ea9e9.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Tom Hanks\\026_bb842452.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Tom Hanks\\035_0902e9ca.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Tom Hanks\\053_5fde0a5b.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Tom Hanks\\059_c7c906d9.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Tom Hanks\\063_c13c362e.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Tom Hanks\\100_b712e7ca.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Will Smith\\026_4f5bfb2c.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Will Smith\\034_32b04ae9.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Will Smith\\042_f6cff42f.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Will Smith\\054_cbee29ae.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Will Smith\\055_f9cbb53e.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Will Smith\\061_4385aa8d.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Will Smith\\065_5cb55293.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Will Smith\\069_80468bd5.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Will Smith\\074_61fe25d9.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Will Smith\\075_65ffca63.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Will Smith\\079_8575a4bc.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Will Smith\\083_a0692bc1.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Will Smith\\093_dc555290.jpg; skipping.\n",
            "⚠️  No face detected in C:/Users/nandhudivya/Desktop/project/dataset\\Will Smith\\099_d652e3b6.jpg; skipping.\n",
            "Extracted 1702 encodings for 17 people.\n",
            "Classes: ['Angelina Jolie' 'Brad Pitt' 'Denzel Washington' 'Hugh Jackman'\n",
            " 'Jennifer Lawrence' 'Johnny Depp' 'Kate Winslet' 'Leonardo DiCaprio'\n",
            " 'Megan Fox' 'Natalie Portman' 'Nicole Kidman' 'Robert Downey Jr'\n",
            " 'Sandra Bullock' 'Scarlett Johansson' 'Tom Cruise' 'Tom Hanks'\n",
            " 'Will Smith']\n",
            "Epoch 1/10 — loss: 2.7539, val_acc: 0.1144\n",
            "Epoch 2/10 — loss: 2.2006, val_acc: 0.7947\n",
            "Epoch 3/10 — loss: 1.3457, val_acc: 0.9560\n",
            "Epoch 4/10 — loss: 0.7786, val_acc: 0.9736\n",
            "Epoch 5/10 — loss: 0.4449, val_acc: 0.9736\n",
            "Epoch 6/10 — loss: 0.2884, val_acc: 0.9824\n",
            "Epoch 7/10 — loss: 0.2046, val_acc: 0.9824\n",
            "Epoch 8/10 — loss: 0.1426, val_acc: 0.9883\n",
            "Epoch 9/10 — loss: 0.1144, val_acc: 0.9912\n",
            "Epoch 10/10 — loss: 0.0876, val_acc: 0.9912\n",
            "Best val acc: 0.9912\n",
            "Accuracy: 0.9912023460410557\n",
            "Classification report:\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "    Angelina Jolie       0.95      1.00      0.97        19\n",
            "         Brad Pitt       1.00      1.00      1.00        19\n",
            " Denzel Washington       0.95      1.00      0.97        18\n",
            "      Hugh Jackman       1.00      1.00      1.00        19\n",
            " Jennifer Lawrence       1.00      1.00      1.00        19\n",
            "       Johnny Depp       1.00      1.00      1.00        19\n",
            "      Kate Winslet       0.95      1.00      0.97        19\n",
            " Leonardo DiCaprio       1.00      1.00      1.00        19\n",
            "         Megan Fox       1.00      0.89      0.94        19\n",
            "   Natalie Portman       1.00      1.00      1.00        19\n",
            "     Nicole Kidman       1.00      1.00      1.00        19\n",
            "  Robert Downey Jr       1.00      1.00      1.00        19\n",
            "    Sandra Bullock       1.00      1.00      1.00        19\n",
            "Scarlett Johansson       1.00      1.00      1.00        39\n",
            "        Tom Cruise       1.00      1.00      1.00        20\n",
            "         Tom Hanks       1.00      1.00      1.00        19\n",
            "        Will Smith       1.00      0.94      0.97        17\n",
            "\n",
            "          accuracy                           0.99       341\n",
            "         macro avg       0.99      0.99      0.99       341\n",
            "      weighted avg       0.99      0.99      0.99       341\n",
            "\n",
            "Confusion matrix:\n",
            "[[19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 18  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 19  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 19  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 19  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0]\n",
            " [ 1  0  0  0  0  0  1  0 17  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 39  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 19  0]\n",
            " [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0 16]]\n",
            "Saved model and label encoder to C:/Users/nandhudivya/Desktop/project/saved_models\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "DATASET_DIR = r\"C:/Users/nandhudivya/Desktop/project/dataset\"\n",
        "SAVEDIR = \"C:/Users/nandhudivya/Desktop/project/saved_models\"\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "LR = 1e-3\n",
        "TEST_SIZE = 0.2\n",
        "RANDOM_STATE = 42\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "os.makedirs(SAVEDIR, exist_ok=True)\n",
        "\n",
        "\n",
        "# Extractraction of face encodings for each image\n",
        "\n",
        "def extract_encodings(dataset_dir):\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    persons = sorted([d for d in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, d))])\n",
        "    if not persons:\n",
        "        raise RuntimeError(f\"No person subfolders found in {dataset_dir}. Expect dataset/person_name/*.jpg\")\n",
        "\n",
        "    for person in persons:\n",
        "        person_dir = os.path.join(dataset_dir, person)\n",
        "        image_files = []\n",
        "\n",
        "        for ext in (\"*.jpg\", \"*.jpeg\", \"*.png\"):\n",
        "            image_files.extend(glob.glob(os.path.join(person_dir, ext)))\n",
        "        if not image_files:\n",
        "            print(f\"Warning: no images found in {person_dir}\")\n",
        "            continue\n",
        "\n",
        "        for img_path in image_files:\n",
        "\n",
        "            try:\n",
        "                img = face_recognition.load_image_file(img_path)\n",
        "            except Exception as e:\n",
        "                print(f\"Could not load {img_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "\n",
        "            encs = face_recognition.face_encodings(img)\n",
        "            if len(encs) == 0:\n",
        "\n",
        "                print(f\"⚠️  No face detected in {img_path}; skipping.\")\n",
        "                continue\n",
        "\n",
        "\n",
        "            encoding = encs[0]\n",
        "            X.append(encoding)\n",
        "            y.append(person)\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    print(f\"Extracted {len(X)} encodings for {len(np.unique(y))} people.\")\n",
        "    return X, y\n",
        "\n",
        "\n",
        "# Building dataset and encoding labels\n",
        "\n",
        "def build_dataset(X, y, test_size=TEST_SIZE):\n",
        "    le = LabelEncoder()\n",
        "    y_enc = le.fit_transform(y)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=test_size, random_state=RANDOM_STATE, stratify=y_enc)\n",
        "\n",
        "    X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "    y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
        "    X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
        "    y_test_t = torch.tensor(y_test, dtype=torch.long)\n",
        "    return (X_train_t, y_train_t), (X_test_t, y_test_t), le\n",
        "\n",
        "\n",
        "#  Simple MLP classifier (ANN):\n",
        "class FaceNetMLP(nn.Module):\n",
        "    def __init__(self, input_dim=128, hidden_dims=(256,128), num_classes=2, dropout=0.3):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        prev = input_dim\n",
        "        for h in hidden_dims:\n",
        "            layers.append(nn.Linear(prev, h))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "            prev = h\n",
        "        layers.append(nn.Linear(prev, num_classes))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "# Training loop\n",
        "\n",
        "def train_model(model, train_loader, val_loader, epochs=EPOCHS, lr=LR, device=DEVICE):\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    best_state = None\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(xb)\n",
        "            loss = criterion(logits, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * xb.size(0)\n",
        "\n",
        "        avg_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "        # Model-Validation\n",
        "        model.eval()\n",
        "        preds = []\n",
        "        trues = []\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                logits = model(xb)\n",
        "                pred = torch.argmax(logits, dim=1)\n",
        "                preds.extend(pred.cpu().numpy())\n",
        "                trues.extend(yb.cpu().numpy())\n",
        "        val_acc = accuracy_score(trues, preds)\n",
        "        print(f\"Epoch {epoch}/{epochs} — loss: {avg_loss:.4f}, val_acc: {val_acc:.4f}\")\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_state = model.state_dict()\n",
        "\n",
        "    # best-Load\n",
        "    if best_state:\n",
        "        model.load_state_dict(best_state)\n",
        "    print(f\"Best val acc: {best_val_acc:.4f}\")\n",
        "    return model\n",
        "\n",
        "\n",
        "#Evaluation helper\n",
        "\n",
        "def evaluate(model, X_test_t, y_test_t, le, device=DEVICE):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    with torch.no_grad():\n",
        "        xb = X_test_t.to(device)\n",
        "        logits = model(xb)\n",
        "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "        trues = y_test_t.numpy()\n",
        "\n",
        "    print(\"Accuracy:\", accuracy_score(trues, preds))\n",
        "    print(\"Classification report:\")\n",
        "    print(classification_report(trues, preds, target_names=le.classes_))\n",
        "    print(\"Confusion matrix:\")\n",
        "    print(confusion_matrix(trues, preds))\n",
        "\n",
        "\n",
        "# single image-Inference\n",
        "\n",
        "def predict_image(model, image_path, le, device=DEVICE):\n",
        "    img = face_recognition.load_image_file(image_path)\n",
        "    encs = face_recognition.face_encodings(img)\n",
        "    if len(encs) == 0:\n",
        "        print(\"No face detected.\")\n",
        "        return None\n",
        "    enc = torch.tensor(encs[0], dtype=torch.float32).unsqueeze(0).to(device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(enc)\n",
        "        prob = torch.softmax(logits, dim=1)\n",
        "        pred_idx = int(torch.argmax(prob, dim=1).cpu().numpy()[0])\n",
        "        confidence = float(prob[0, pred_idx].cpu().numpy())\n",
        "    name = le.inverse_transform([pred_idx])[0]\n",
        "    return name, confidence\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Device:\", DEVICE)\n",
        "    X, y = extract_encodings(DATASET_DIR)\n",
        "    if len(X) == 0:\n",
        "        raise RuntimeError(\"No encodings extracted. Check dataset and face detection.\")\n",
        "\n",
        "    (X_train_t, y_train_t), (X_test_t, y_test_t), le = build_dataset(X, y)\n",
        "\n",
        "    num_classes = len(le.classes_)\n",
        "    print(\"Classes:\", le.classes_)\n",
        "\n",
        "    train_ds = TensorDataset(X_train_t, y_train_t)\n",
        "    test_ds = TensorDataset(X_test_t, y_test_t)\n",
        "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # Creation of Model\n",
        "    model = FaceNetMLP(input_dim=128, hidden_dims=(256,128), num_classes=num_classes, dropout=0.3)\n",
        "\n",
        "    # Model-training:\n",
        "    model = train_model(model, train_loader, test_loader, epochs=EPOCHS, lr=LR, device=DEVICE)\n",
        "\n",
        "    # Model-evaluation:\n",
        "    evaluate(model, X_test_t, y_test_t, le, device=DEVICE)\n",
        "\n",
        "    # Model-Save & Label encoding:\n",
        "    torch.save(model.state_dict(), os.path.join(SAVEDIR, \"ann_face_recognition.pt\"))\n",
        "    with open(os.path.join(SAVEDIR, \"label_encoder.pkl\"), \"wb\") as f:\n",
        "        pickle.dump(le, f)\n",
        "    print(\"Saved model and label encoder to\", SAVEDIR)\n",
        "\n",
        "\n",
        "    sample_image = os.path.join(DATASET_DIR, os.listdir(DATASET_DIR)[0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Single Image Face Recognition: Model Inference and Prediction**"
      ],
      "metadata": {
        "id": "6tV4yboahdM3"
      },
      "id": "6tV4yboahdM3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c76eb18a-f32b-4b03-87b0-08dfb9daad7d",
      "metadata": {
        "id": "c76eb18a-f32b-4b03-87b0-08dfb9daad7d",
        "outputId": "a9736b77-47fb-45a3-d3d9-0331ca802d91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model and label encoder loaded successfully. Classes: ['Angelina Jolie' 'Brad Pitt' 'Denzel Washington' 'Hugh Jackman'\n",
            " 'Jennifer Lawrence' 'Johnny Depp' 'Kate Winslet' 'Leonardo DiCaprio'\n",
            " 'Megan Fox' 'Natalie Portman' 'Nicole Kidman' 'Robert Downey Jr'\n",
            " 'Sandra Bullock' 'Scarlett Johansson' 'Tom Cruise' 'Tom Hanks'\n",
            " 'Will Smith']\n",
            "🧠 Predicted person: Angelina Jolie\n",
            "🎯 Confidence: 0.9908\n"
          ]
        }
      ],
      "source": [
        "#Config\n",
        "MODEL_PATH = \"C:/Users/nandhudivya/Desktop/project/saved_models/ann_face_recognition.pt\"\n",
        "ENCODER_PATH = \"C:/Users/nandhudivya/Desktop/project/saved_models/label_encoder.pkl\"\n",
        "TEST_IMAGE = \"C:/Users/nandhudivya/Desktop/project/test_img/anjel.jpg\"\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Model Loading and label encoding\n",
        "\n",
        "with open(ENCODER_PATH, \"rb\") as f:\n",
        "    label_encoder = pickle.load(f)\n",
        "\n",
        "num_classes = len(label_encoder.classes_)\n",
        "model = FaceNetMLP(input_dim=128, num_classes=num_classes)\n",
        "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
        "model.to(DEVICE)\n",
        "model.eval()\n",
        "\n",
        "print(f\"✅ Model and label encoder loaded successfully. Classes: {label_encoder.classes_}\")\n",
        "\n",
        "# Extraction\n",
        "\n",
        "try:\n",
        "    image = face_recognition.load_image_file(TEST_IMAGE)\n",
        "except Exception as e:\n",
        "    raise SystemExit(f\"❌ Could not load test image: {e}\")\n",
        "\n",
        "encodings = face_recognition.face_encodings(image)\n",
        "if len(encodings) == 0:\n",
        "    raise SystemExit(\"⚠️ No face found in the test image.\")\n",
        "\n",
        "encoding = encodings[0]\n",
        "input_tensor = torch.tensor(encoding, dtype=torch.float32).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "# Prediction\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(input_tensor)\n",
        "    probs = torch.softmax(logits, dim=1)\n",
        "    pred_idx = torch.argmax(probs, dim=1).item()\n",
        "    confidence = probs[0, pred_idx].item()\n",
        "\n",
        "pred_name = label_encoder.inverse_transform([pred_idx])[0]\n",
        "\n",
        "#Result\n",
        "print(f\"🧠 Predicted person: {pred_name}\")\n",
        "print(f\"🎯 Confidence: {confidence:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Batch Prediction: Face Recognition on Multiple Images**"
      ],
      "metadata": {
        "id": "KCG-0SKyiTyd"
      },
      "id": "KCG-0SKyiTyd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a11a538d-0666-42c5-9ad5-f721229b015a",
      "metadata": {
        "id": "a11a538d-0666-42c5-9ad5-f721229b015a",
        "outputId": "74a9fe67-05fe-41f9-97dc-02dbe3a9865c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "anjel.jpg → Angelina Jolie (confidence: 0.991)\n",
            "Brad Pitt.jpg → Brad Pitt (confidence: 0.995)\n",
            "Denzel Washington.jpg → Denzel Washington (confidence: 0.989)\n",
            "Hugh Jackman.jpg → Hugh Jackman (confidence: 0.996)\n",
            "Jennifer Lawrence.jpg → Jennifer Lawrence (confidence: 0.947)\n",
            "Johnny Depp.jpg → Johnny Depp (confidence: 0.992)\n",
            "Kate Winslet.jpg → Kate Winslet (confidence: 0.954)\n",
            "Leonardo DiCaprio.jpg → Leonardo DiCaprio (confidence: 0.980)\n",
            "Megan Fox.jpg → Megan Fox (confidence: 0.933)\n",
            "Natalie Portman.jpg → Natalie Portman (confidence: 0.997)\n",
            "Nicole Kidman.jpg → Nicole Kidman (confidence: 0.994)\n",
            "Robert Downey Jr..jpg → Robert Downey Jr (confidence: 0.997)\n",
            "Sandra Bullock.jpg → Sandra Bullock (confidence: 0.998)\n",
            "Scarlett Johansson.jpg → Scarlett Johansson (confidence: 1.000)\n",
            "Tom Cruise.jpg → Tom Cruise (confidence: 0.997)\n",
            "Tom Hanks.jpg → Tom Hanks (confidence: 0.986)\n",
            "Will Smith.jpg → Will Smith (confidence: 0.976)\n"
          ]
        }
      ],
      "source": [
        "#Prediction using multiple image\n",
        "\n",
        "with open(ENCODER_PATH, \"rb\") as f:\n",
        "    le = pickle.load(f)\n",
        "\n",
        "num_classes = len(le.classes_)\n",
        "model = FaceNetMLP(input_dim=128, num_classes=num_classes)\n",
        "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
        "model.to(DEVICE)\n",
        "model.eval()\n",
        "\n",
        "for filename in os.listdir(TEST_DIR):\n",
        "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        img_path = os.path.join(TEST_DIR, filename)\n",
        "        img = face_recognition.load_image_file(img_path)\n",
        "        encs = face_recognition.face_encodings(img)\n",
        "        if len(encs) == 0:\n",
        "            print(f\"⚠️ No face in {filename}\")\n",
        "            continue\n",
        "        enc = torch.tensor(encs[0], dtype=torch.float32).unsqueeze(0).to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            logits = model(enc)\n",
        "            probs = torch.softmax(logits, dim=1)\n",
        "            pred_idx = torch.argmax(probs, dim=1).item()\n",
        "\n",
        "            conf = probs[0, pred_idx].item()\n",
        "        name = le.inverse_transform([pred_idx])[0]\n",
        "        print(f\"{filename} → {name} (confidence: {conf:.3f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Face Recognition with Personal Details Lookup from CSV**"
      ],
      "metadata": {
        "id": "rxbu35Iwi9o_"
      },
      "id": "rxbu35Iwi9o_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8638d514-df49-4f18-84ef-606426e5085d",
      "metadata": {
        "id": "8638d514-df49-4f18-84ef-606426e5085d",
        "outputId": "69a3bd2e-e78a-4e1a-d8ad-ad9c1f577eb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "anjel.jpg → Angelina Jolie (confidence: 0.991) | Age: 53, gender: female, Nationality: American\n",
            "Brad Pitt.jpg → Brad Pitt (confidence: 0.995) | Age: 45, gender: male, Nationality: American\n",
            "Denzel Washington.jpg → Denzel Washington (confidence: 0.989) | Age: 38, gender: male, Nationality: American\n",
            "Hugh Jackman.jpg → Hugh Jackman (confidence: 0.996) | Age: 37, gender: male, Nationality: Australian\n",
            "Jennifer Lawrence.jpg → Jennifer Lawrence (confidence: 0.947) | Age: 41, gender: female, Nationality: American\n",
            "Johnny Depp.jpg → Johnny Depp (confidence: 0.992) | Age: 36, gender: male, Nationality: American\n",
            "Kate Winslet.jpg → Kate Winslet (confidence: 0.954) | Age: 42, gender: female, Nationality: British\n",
            "Leonardo DiCaprio.jpg → Leonardo DiCaprio (confidence: 0.980) | Age: 34, gender: male, Nationality: American\n",
            "Megan Fox.jpg → Megan Fox (confidence: 0.933) | Age: 35, gender: female, Nationality: American\n",
            "Natalie Portman.jpg → Natalie Portman (confidence: 0.997) | Age: 30, gender: female, Nationality: Israeli-American\n",
            "Nicole Kidman.jpg → Nicole Kidman (confidence: 0.994) | Age: 40, gender: female, Nationality: Australian\n",
            "Robert Downey Jr..jpg → Robert Downey Jr (confidence: 0.997) | Age: 54, gender: male, Nationality: American\n",
            "Sandra Bullock.jpg → Sandra Bullock (confidence: 0.998) | Age: 46, gender: female, Nationality: American\n",
            "Scarlett Johansson.jpg → Scarlett Johansson (confidence: 1.000) | Age: 36, gender: female, Nationality: American\n",
            "Tom Cruise.jpg → Tom Cruise (confidence: 0.997) | Age: 43, gender: male, Nationality: American\n",
            "Tom Hanks.jpg → Tom Hanks (confidence: 0.986) | Age: 39, gender: male, Nationality: American\n",
            "Will Smith.jpg → Will Smith (confidence: 0.976) | Age: 48, gender: male, Nationality: American\n"
          ]
        }
      ],
      "source": [
        "# Prediction using image and person info\n",
        "\n",
        "CSV_PATH = \"C:/Users/nandhudivya/Desktop/project/actors.csv\"\n",
        "\n",
        "# Model-Loading\n",
        "with open(ENCODER_PATH, \"rb\") as f:\n",
        "    le = pickle.load(f)\n",
        "\n",
        "num_classes = len(le.classes_)\n",
        "model = FaceNetMLP(input_dim=128, num_classes=num_classes)\n",
        "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
        "model.to(DEVICE)\n",
        "model.eval()\n",
        "\n",
        "# Loading presonal details-CSV\n",
        "df = pd.read_csv(\"C:/Users/nandhudivya/Desktop/project/actors.csv\")\n",
        "df.columns = df.columns.str.strip().str.lower()\n",
        "df['name'] = df['name'].str.strip().str.lower()\n",
        "df = df.drop_duplicates(subset='name')\n",
        "df.set_index('name', inplace=True)\n",
        "\n",
        "\n",
        "# Test Image\n",
        "for filename in os.listdir(TEST_DIR):\n",
        "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        img_path = os.path.join(TEST_DIR, filename)\n",
        "        img = face_recognition.load_image_file(img_path)\n",
        "        encs = face_recognition.face_encodings(img)\n",
        "        if len(encs) == 0:\n",
        "            print(f\"⚠️ No face in {filename}\")\n",
        "            continue\n",
        "        enc = torch.tensor(encs[0], dtype=torch.float32).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(enc)\n",
        "            probs = torch.softmax(logits, dim=1)\n",
        "            pred_idx = torch.argmax(probs, dim=1).item()\n",
        "            confidence = probs[0, pred_idx].item()\n",
        "\n",
        "        pred_name = le.inverse_transform([pred_idx])[0]\n",
        "\n",
        "        pred_name_clean = pred_name.strip().lower()\n",
        "\n",
        "        row = df[df.index == pred_name_clean]\n",
        "\n",
        "\n",
        "        name = le.inverse_transform([pred_idx])[0].strip().lower()\n",
        "        if name in df.index:\n",
        "            row = df.loc[name]\n",
        "            gender = row['gender']\n",
        "            nationality = row['nationality']\n",
        "            age = row['age']\n",
        "        else:\n",
        "            gender, nationality, age = \"Unknown\", \"Unknown\", \"Unknown\"\n",
        "\n",
        "\n",
        "        print(f\"{filename} → {pred_name} (confidence: {confidence:.3f}) | Age: {age}, gender: {gender}, Nationality: {nationality}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Project Results Summary**\n",
        "\n",
        "Dataset: 1,702 face encodings for 17 celebrities.\n",
        "\n",
        "Model: MLP classifier trained on FaceNet embeddings.\n",
        "\n",
        "Performance: Final accuracy 99.12%; most individuals classified with high precision and recall.\n",
        "\n",
        "Prediction: Single and batch images predicted correctly with high confidence (93–100%).\n",
        "\n",
        "Additional Info: Age, gender, and nationality successfully retrieved from CSV for each person."
      ],
      "metadata": {
        "id": "K4pwgXZKkrRD"
      },
      "id": "K4pwgXZKkrRD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "\n",
        "The system accurately recognizes faces and retrieves personal information with high confidence. It demonstrates the effective combination of deep learning embeddings and structured data, providing a reliable and practical solution for face recognition applications."
      ],
      "metadata": {
        "id": "OMG_p8x7kt_R"
      },
      "id": "OMG_p8x7kt_R"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "PyTorch (GPU)",
      "language": "python",
      "name": "pytorch_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}